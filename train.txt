from sklearn.neural_network import MLPRegressor

nn_model = MLPRegressor(hidden_layer_sizes=(64, 32, 16), activation='relu', max_iter=500, random_state=42)
nn_model.fit(X_train, y_train)

# Predictions
y_pred_nn = nn_model.predict(X_test)

# Evaluate Model
mse_nn = mean_squared_error(y_test, y_pred_nn)
print(f"Neural Network MSE: {mse_nn:.5f}")

from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import GridSearchCV

# Define hyperparameter grid
rf_params = {
    "n_estimators": [50, 100, 200],  # Number of trees
    "max_depth": [10, 20, None],  # Depth of tree
    "min_samples_split": [2, 5, 10],  # Minimum samples to split a node
}

# Initialize model
rf = RandomForestRegressor(random_state=42)

# Grid Search
grid_search_rf = GridSearchCV(rf, rf_params, cv=3, scoring="neg_mean_squared_error", n_jobs=-1, verbose=2)
grid_search_rf.fit(X_train, y_train)

# Best Parameters
print("Best Parameters for Random Forest:", grid_search_rf.best_params_)

# Train with best parameters
best_rf = grid_search_rf.best_estimator_

sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import RandomizedSearchCV

# Define hyperparameter grid
dt_params = {
    "max_depth": [5, 10, 20, None],
    "min_samples_split": [2, 5, 10],
    "min_samples_leaf": [1, 2, 4]
}from

# Initialize model
dt = DecisionTreeRegressor(random_state=42)

# Randomized Search
random_search_dt = RandomizedSearchCV(dt, dt_params, n_iter=10, cv=3, scoring="neg_mean_squared_error", n_jobs=-1, random_state=42, verbose=2)
random_search_dt.fit(X_train, y_train)

# Best Parameters
print("Best Parameters for Decision Tree:", random_search_dt.best_params_)

# Train with best parameters
best_dt = random_search_dt.best_estimator_

from sklearn.neural_network import MLPRegressor

# Define hyperparameter grid
nn_params = {
    "hidden_layer_sizes": [(64,), (128, 64), (128, 64, 32)],  # Layer sizes
    "activation": ["relu", "tanh"],  # Activation functions
    "alpha": [0.0001, 0.001, 0.01],  # Regularization term
    "learning_rate": ["constant", "adaptive"],  # Learning rate type
}

# Initialize model
nn = MLPRegressor(max_iter=500, random_state=42)

# Grid Search
grid_search_nn = GridSearchCV(nn, nn_params, cv=3, scoring="neg_mean_squared_error", n_jobs=-1, verbose=2)
grid_search_nn.fit(X_train, y_train)

# Best Parameters
print("Best Parameters for Neural Network:", grid_search_nn.best_params_)

# Train with best parameters
best_nn = grid_search_nn.best_estimator_

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

# Define the Neural Network
model = keras.Sequential([
    layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),
    layers.Dense(64, activation='relu'),
    layers.Dense(32, activation='relu'),
    layers.Dense(1)  # Output layer
])

# Compile Model
model.compile(optimizer='adam', loss='mse', metrics=['mae'])

# Train the Model
history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)

# Evaluate Model
mse, mae = model.evaluate(X_test, y_test)
print(f"TensorFlow Model - MSE: {mse:.5f}, MAE: {mae:.5f}")

grid = GridSearchCV(XGBRegressor(), param_grid=params, cv=3, scoring='neg_mean_absolute_error')
grid.fit(X_train, y_train)

print("Best Parameters:", grid.best_params_)